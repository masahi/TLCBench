This directory stores good models for benchmarking.

- [Int8 BERT quantized with Quantization-Aware training](bert-base-qat.onnx) following the steps in https://github.com/NVIDIA/FasterTransformer/tree/main/bert-quantization/bert-pyt-quantization#quantization-aware-fine-tuning and converted to ONNX.
- [EfficientNetv2-S](efficientnetv2-s.onnx), the original TF2 model is from https://github.com/google/automl/tree/master/efficientnetv2 and converted to ONNX following the steps in https://github.com/NVIDIA/TensorRT/tree/master/samples/python/efficientnet#2-efficientnet-v2
